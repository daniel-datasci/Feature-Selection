{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "97719c149fb0e0c81daec5c71463385b1900022c"
   },
   "source": [
    "# Feature selection - Correlation and P value : Daniel Ifediba\n",
    "\n",
    "Often when we get a dataset, we might find a plethora of features in the dataset. All of the features we find in the dataset might not be useful in building a machine learning model to make the necessary prediction. Using some of the features might even make the predictions worse. So, feature selection plays a huge role in building a machine learning model.\n",
    "\n",
    "In this kernel we will explore two measures that we can use on the data to select the right features.\n",
    "\n",
    "## Contents\n",
    "1. [Correlation](#1)\n",
    "    1. [What is Correlation?](#1-1)\n",
    "    2. [How does correlation help in feature selection?](#1-2)\n",
    "2. [P-value](#2)\n",
    "    1. [What is p-value?](#2-1)\n",
    "    2. [How does p-value help in feature selection?](#2-2)\n",
    "3. [Implementation](#3)\n",
    "    1. [The dataset](#3-1)\n",
    "    2. [Selecting feaatures based on correlation](#3-2)\n",
    "    3. [Selecting features based on p-value](#3-3)\n",
    "    4. [Visualizing the selected features](#3-4)\n",
    "    5. [Building  model with the selected features](#3-5)\n",
    "    6. [Building model without feature selection and comparing the results](#3-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9dd9e07c590ca22f0c525222f60f0ebff4e092c6"
   },
   "source": [
    "<a id=\"1\"></a> \n",
    "## Correlation\n",
    "<a id=\"1-1\"></a>\n",
    "### What is correlation?\n",
    "Correlation is a statistical term which in common usage refers to how close two variables are to having a linear relationship with each other.\n",
    "\n",
    "For example, two variables which are linearly dependent (say, **x** and **y** which depend on each other as x = 2y) will have a higher correlation than two variables which are non-linearly dependent (say, u and v which depend on each other as u = v2)\n",
    "<a id=\"1-2\"></a>\n",
    "### How does correlation help in feature selection?\n",
    "Features with high correlation are more linearly dependent and hence have almost the same effect on the dependent variable. So, when two features have high correlation, we can drop one of the two features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2b702189d861336692d0f9441fa673f2326e6f96"
   },
   "source": [
    "<a id=\"2\"></a>\n",
    "## P-value\n",
    "Before we try to understand about about p-value, we need to know about the null hypothesis.\n",
    "\n",
    "**Null hypothesis** is a general statement that there is no relationship between two measured phenomena. \n",
    ">Testing (accepting, approving, rejecting, or disproving) the null hypothesis—and thus concluding that there are or are not grounds for believing that there is a relationship between two phenomena (e.g. that a potential treatment has a measurable effect)—is a central task in the modern practice of science; the field of statistics gives precise criteria for rejecting a null hypothesis.\n",
    "\n",
    "*Source: [Wikipedia](https://en.wikipedia.org/wiki/Null_hypothesis)*\n",
    "\n",
    "For more info about the null hypothesis check the above Wikipedia article\n",
    "\n",
    "\n",
    "<a id=\"2-1\"></a>\n",
    "### What is p-value?\n",
    "P-value or probability value or asymptotic significance is a probability value  for a given statistical model that, if the null hyothesis is true, a set of statistical observations more commonly known as the [statistical summary](https://en.wikipedia.org/wiki/Summary_statistics) is greater than or equal in magnitude to the observed results. \n",
    "<a id=\"2-2\"></a>\n",
    "### How does p-value help in feature selection?\n",
    "Removal of different features from the dataset will have different effects on the p-value for the dataset. We can remove different features and measure the p-value in each case. These measured p-values can be used to decide whether to keep a feature or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c2d0b43d30fa33c595876fb75153b1523b858ce7"
   },
   "source": [
    "<a id=\"3\"></a>\n",
    "## Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a607218412fd4afe70ba2b09a24e12e827774aa1"
   },
   "source": [
    "### Import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_uuid": "3e410c3508beb0ff1c681badbacb4e0d32ceeb0a"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5b902e77df56a03ee28a1e052efba3319ebc7391"
   },
   "source": [
    "The `numpy.random.seed()` makes the random numbers predictable and is used for reproducibility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "657fa7508eed66c156ceb44dd5da15ccb74d6e3a"
   },
   "source": [
    "<a id=\"3-1\"></a>\n",
    "## The Dataset\n",
    "The dataset used here is the [Breast Cancer Wisconsin (Diagnostic) Data Set](https://www.kaggle.com/uciml/breast-cancer-wisconsin-data).\n",
    "\n",
    "This dataset contains 569 records of and 32 features (including the Id ). The features represent various parameter that **might** be useful in predicting if a tumor is malignant or benign."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c3fb5c911a3ab7c120bc3e0abe013e68174776a0"
   },
   "source": [
    "### Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "f9e7bd1069bcc06d3ccb816ae5b6ba6d84041386"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../input/data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\DATASC~1\\AppData\\Local\\Temp/ipykernel_200/184295251.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../input/data.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 586\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    587\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 482\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    483\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    484\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    810\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 811\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    812\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1038\u001b[0m             )\n\u001b[0;32m   1039\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1040\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1042\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m    220\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \"\"\"\n\u001b[1;32m--> 222\u001b[1;33m         self.handles = get_handle(\n\u001b[0m\u001b[0;32m    223\u001b[0m             \u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    700\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m\"b\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 702\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    703\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../input/data.csv'"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('../input/data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "abf818acd5b9752cb1baa879e11cb21e29c1f30b"
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b8c52a2a18b253cb606aca7b3a3a5fa48ca8f0e0"
   },
   "source": [
    "Removing the Id and the Unnamed columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "30a5f63e2243d54f5a74b7f9d33b952c9ae57016"
   },
   "outputs": [],
   "source": [
    "data = data.iloc[:,1:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2499434158d5acf41209b7225e3dcbcdbb32186e"
   },
   "source": [
    "Next, we encode the [Categorical Variable](https://en.wikipedia.org/wiki/Categorical_variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8bab65e1ac9710cbf92c126f78ffdb766cd76fd7"
   },
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "data.iloc[:,0] = label_encoder.fit_transform(data.iloc[:,0]).astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8e5b456860d5946e3659979beccf4508332cba0e"
   },
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1783019dec15f155b97050626ef60551f1d5f3c4"
   },
   "source": [
    "<a id=\"3-2\"></a>\n",
    "## Selecting features based on correlation\n",
    "Generating the correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "083036d67602027661d7cf882653dbb74644315c"
   },
   "outputs": [],
   "source": [
    "corr = data.corr()\n",
    "corr.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9b527f6897c96ee3c2ad177a6ff8b534ea48a537"
   },
   "source": [
    "Generating the correlation heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7d4de17f2e5239e465cbd16d8f69b336e8bc9ee5"
   },
   "outputs": [],
   "source": [
    "sns.heatmap(corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "487cbebdc5561f76d83ae2911dda555ef2971168"
   },
   "source": [
    "Next, we compare the correlation between features and remove one of two features that have a correlation higher than 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "455d0943dca0bd6acffa4e5c311177f302aa0ff1"
   },
   "outputs": [],
   "source": [
    "columns = np.full((corr.shape[0],), True, dtype=bool)\n",
    "for i in range(corr.shape[0]):\n",
    "    for j in range(i+1, corr.shape[0]):\n",
    "        if corr.iloc[i,j] >= 0.9:\n",
    "            if columns[j]:\n",
    "                columns[j] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "04ac00d25fc72d1ed799859ffc30a6a7cd250b6e"
   },
   "outputs": [],
   "source": [
    "selected_columns = data.columns[columns]\n",
    "selected_columns.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3fdc13d2628d95f6d7cd7764d5eecd487e9a8bb0"
   },
   "source": [
    "Above, we can see that only 21 columns were selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c4d59498f6e444ccdf130fd8ebc2169447c14a32"
   },
   "outputs": [],
   "source": [
    "data = data[selected_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "154b5c40af45ce83fbc3111b7b4bb3adb3d0df06"
   },
   "source": [
    "Now, the dataset has only those columns with correlation less than 0.9\n",
    "\n",
    "<a id=\"3-3\"></a>\n",
    "## Selecting columns based on p-value\n",
    "Next we will be selecting the columns based on how they affect the p-value. We are the removing the column `diagnosis` because it is the column we are trying to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "307ad1c0679c758458eaaed4262581a231c647d6"
   },
   "outputs": [],
   "source": [
    "selected_columns = selected_columns[1:].values         # Removing the dignosis column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d1b8bb41b3a5679c4b81c29771304f86be33427c"
   },
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as sm\n",
    "def backwardElimination(x, Y, sl, columns):\n",
    "    numVars = len(x[0])\n",
    "    for i in range(0, numVars):\n",
    "        regressor_OLS = sm.OLS(Y, x).fit()\n",
    "        maxVar = max(regressor_OLS.pvalues).astype(float)\n",
    "        if maxVar > sl:\n",
    "            for j in range(0, numVars - i):\n",
    "                if (regressor_OLS.pvalues[j].astype(float) == maxVar):\n",
    "                    x = np.delete(x, j, 1)\n",
    "                    columns = np.delete(columns, j)\n",
    "                    \n",
    "    regressor_OLS.summary()\n",
    "    return x, columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "222fe5cf29329a0802e161ae312f09b1dbb28b41"
   },
   "outputs": [],
   "source": [
    "SL = 0.05\n",
    "data_modeled, selected_columns = backwardElimination(data.iloc[:,1:].values, data.iloc[:,0].values, SL, selected_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ab66b1a3fe6b3f4033fcd8081a952b0531b0ae24"
   },
   "source": [
    "Moving the result to a new dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "bf33d3c3e94ef38c467370880d3199a3a972065b"
   },
   "outputs": [],
   "source": [
    "result = pd.DataFrame()\n",
    "result['diagnosis'] = data.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "26a49c01882b7ed370897d788e1afba36bd14c7f"
   },
   "source": [
    "Creating a dataframe with the columns selected using the p-value and correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e34d076a237c42791178625f8e020c903ce249da"
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame(data = data_modeled, columns = selected_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "178407cc6b5e7ee3de1da4451c358d6d8a6b5a19"
   },
   "source": [
    "<a id=\"3-4\"></a>\n",
    "## Visualizing the selected features\n",
    "Plotting the data to visualize their distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ce793b8f8e6cca7099094e5798884ed09a74e416"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (20, 25))\n",
    "j = 0\n",
    "for i in data.columns:\n",
    "    plt.subplot(6, 4, j+1)\n",
    "    j += 1\n",
    "    sns.distplot(data[i][result['diagnosis']==0], color='g', label = 'benign')\n",
    "    sns.distplot(data[i][result['diagnosis']==1], color='r', label = 'malignant')\n",
    "    plt.legend(loc='best')\n",
    "fig.suptitle('Breast Cance Data Analysis')\n",
    "fig.tight_layout()\n",
    "fig.subplots_adjust(top=0.95)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "edc9a44c58fa05255d740cb60ace232f6f349cf3"
   },
   "source": [
    "Now we split the data to train and test set. 20% of the data is used to create the test data and 80% to create the train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2add1d7fc420bbce550904a7a9b3fba4a03df6aa"
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(data.values, result.values, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0cef6534bcf5e7163471afdded212d640ff6b7ac"
   },
   "source": [
    "<a id=\"3-5\"></a>\n",
    "## Building a model with the selected features\n",
    "We are using a [Support Vector Classifier](https://en.wikipedia.org/wiki/Support_vector_machine) with a [Gaussian Kernel](https://en.wikipedia.org/wiki/Gaussian_function) to make the predictions. We will train the model on our train data and calculate the accuracy of the model using the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b309c3e9e6792e0a77ead881ebdeba389c5e6090"
   },
   "outputs": [],
   "source": [
    "svc = SVC()              # The default kernel used by SVC is the gaussian kernel\n",
    "svc.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a825102e3ba3ec07cf73391ba32898448a1d6437"
   },
   "source": [
    "Making the predictions and calculating the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2761b281c43e0420ba7bc11a81410ef9f364d8b9"
   },
   "outputs": [],
   "source": [
    "prediction = svc.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6e7b5d28c7cab366694a0b48d9cd393c32c5588f"
   },
   "source": [
    "We are using a [confusion matrix](https://en.wikipedia.org/wiki/Confusion_matrix) here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "50d6c6be368067bc26e3326010eb3811f115e5ef"
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, prediction)\n",
    "sum = 0\n",
    "for i in range(cm.shape[0]):\n",
    "    sum += cm[i][i]\n",
    "    \n",
    "accuracy = sum/x_test.shape[0]\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7b8f78ed1b64bc2a6da096831a863b5969ca5f06"
   },
   "source": [
    "<a id=\"3-6\"></a>\n",
    "## Building a model without feature selection and comparing the results\n",
    "Next, we repeat all the above steps except feature selection, which are:\n",
    "* Loading the data\n",
    "* Removing the unwanted columns\n",
    "* Encoding the categorical variable\n",
    "* Splitting the data into train and test set\n",
    "* Fitting the data to the model\n",
    "* Making the predictions and calculating the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "62b6aba135729480fead5738ac8910e578b47d73"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('../input/data.csv')          \n",
    "result = pd.DataFrame()\n",
    "result['diagnosis'] = data.iloc[:,1]\n",
    "data = data.iloc[:,2:-1]                         \n",
    "label_encoder = LabelEncoder()              \n",
    "data.iloc[:,0] = label_encoder.fit_transform(data.iloc[:,0]).astype('float64')    \n",
    "x_train, x_test, y_train, y_test = train_test_split(data.values, result.values, test_size = 0.2)      \n",
    "svc = SVC()\n",
    "svc.fit(x_train, y_train)                        \n",
    "prediction = svc.predict(x_test)                 \n",
    "cm = confusion_matrix(y_test, prediction)        \n",
    "sum = 0\n",
    "for i in range(cm.shape[0]):\n",
    "    sum += cm[i][i]\n",
    "    \n",
    "accuracy = sum/x_test.shape[0]                \n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3dbed0f49922ecd221642c069bfe87f7a5e28194"
   },
   "source": [
    "Here we can see that the accuracy of the predictions is better when proper feature selection is performed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
